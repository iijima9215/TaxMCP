#!/usr/bin/env python3
"""
å¤–éƒ¨ãƒ†ã‚¹ãƒˆç’°å¢ƒç”¨çµ±åˆãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆ
å…¨ã¦ã®æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆã€èªè¨¼ãƒ†ã‚¹ãƒˆã‚’çµ±åˆå®Ÿè¡Œã—ã¾ã™ã€‚
"""

import os
import sys
import json
import asyncio
import logging
from typing import Dict, Any, List
from datetime import datetime
from dotenv import load_dotenv
from pathlib import Path

# ç¾åœ¨ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰.envã‚’èª­ã¿è¾¼ã¿
load_dotenv()

# ä»–ã®ãƒ†ã‚¹ãƒˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from external_test_client import ExternalTaxMCPClient
from performance_test import PerformanceTestClient
from auth_test import AuthTestClient

class IntegrationTestSuite:
    """çµ±åˆãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆ"""
    
    def __init__(self):
        self.base_url = os.getenv('BASE_URL', 'https://taxmcp.ami-j2.com')
        self.verbose = os.getenv('VERBOSE_OUTPUT', 'true').lower() == 'true'
        
        # ãƒ†ã‚¹ãƒˆè¨­å®š
        self.run_functional_tests = True
        self.run_performance_tests = True
        self.run_auth_tests = True
        
        # ãƒ­ã‚°è¨­å®š
        self.setup_logging()
        
        # çµæœä¿å­˜ç”¨
        self.test_results = {
            "suite_start_time": datetime.now().isoformat(),
            "base_url": self.base_url,
            "functional_tests": None,
            "performance_tests": None,
            "auth_tests": None,
            "summary": {}
        }
    
    def setup_logging(self):
        """ãƒ­ã‚°è¨­å®š"""
        log_file = f"integration_test_suite_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"
        
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(log_file),
                logging.StreamHandler(sys.stdout)
            ]
        )
        self.logger = logging.getLogger(__name__)
        self.logger.info(f"çµ±åˆãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆãƒ­ã‚°: {log_file}")
    
    async def run_functional_tests(self) -> Dict[str, Any]:
        """æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
        self.logger.info("\n=== æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆé–‹å§‹ ===")
        
        try:
            async with ExternalTaxMCPClient() as client:
                results = await client.run_comprehensive_test()
                
                # çµæœã‚µãƒãƒªãƒ¼
                if results and "results" in results:
                    total_tests = 0
                    successful_tests = 0
                    
                    for iteration_result in results["results"]:
                        for test_name, test_result in iteration_result["tests"].items():
                            total_tests += 1
                            if test_result["success"]:
                                successful_tests += 1
                    
                    success_rate = (successful_tests / total_tests * 100) if total_tests > 0 else 0
                    
                    summary = {
                        "status": "completed",
                        "total_tests": total_tests,
                        "successful_tests": successful_tests,
                        "success_rate": success_rate,
                        "details": results
                    }
                    
                    self.logger.info(f"æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆå®Œäº†: {successful_tests}/{total_tests} æˆåŠŸ ({success_rate:.1f}%)")
                else:
                    summary = {
                        "status": "failed",
                        "error": "ãƒ†ã‚¹ãƒˆçµæœãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ"
                    }
                    self.logger.error("æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆå¤±æ•—: çµæœãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
                
                return summary
                
        except Exception as e:
            self.logger.error(f"æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
            return {
                "status": "error",
                "error": str(e)
            }
    
    async def run_performance_tests(self) -> Dict[str, Any]:
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
        self.logger.info("\n=== ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆé–‹å§‹ ===")
        
        try:
            client = PerformanceTestClient()
            
            # åŒæ™‚è² è·ãƒ†ã‚¹ãƒˆ
            concurrent_results = await client.run_performance_test("concurrent")
            
            if concurrent_results:
                summary = {
                    "status": "completed",
                    "concurrent_test": concurrent_results,
                    "meets_sla": concurrent_results.get("performance_assessment", {}).get("meets_sla", False)
                }
                
                sla_status = "âœ“" if summary["meets_sla"] else "âœ—"
                avg_time = concurrent_results.get("response_times", {}).get("average_ms", 0)
                success_rate = concurrent_results.get("summary", {}).get("success_rate_percent", 0)
                
                self.logger.info(
                    f"ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆå®Œäº†: {sla_status} SLAé”æˆ, "
                    f"å¹³å‡å¿œç­”æ™‚é–“: {avg_time}ms, æˆåŠŸç‡: {success_rate}%"
                )
            else:
                summary = {
                    "status": "failed",
                    "error": "ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆçµæœãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ"
                }
                self.logger.error("ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆå¤±æ•—")
            
            return summary
            
        except Exception as e:
            self.logger.error(f"ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
            return {
                "status": "error",
                "error": str(e)
            }
    
    async def run_auth_tests(self) -> Dict[str, Any]:
        """èªè¨¼ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
        self.logger.info("\n=== èªè¨¼ãƒ†ã‚¹ãƒˆé–‹å§‹ ===")
        
        try:
            async with AuthTestClient() as client:
                results = await client.run_auth_tests()
                
                if results:
                    summary = {
                        "status": "completed",
                        "total_tests": results["total_tests"],
                        "successful_tests": results["successful_tests"],
                        "success_rate": results["success_rate"],
                        "security_issues": results["security_issues"],
                        "details": results
                    }
                    
                    security_status = "âš ï¸" if results["security_issues"] > 0 else "âœ“"
                    
                    self.logger.info(
                        f"èªè¨¼ãƒ†ã‚¹ãƒˆå®Œäº†: {results['successful_tests']}/{results['total_tests']} æˆåŠŸ "
                        f"({results['success_rate']:.1f}%), {security_status} ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å•é¡Œ: {results['security_issues']}ä»¶"
                    )
                else:
                    summary = {
                        "status": "failed",
                        "error": "èªè¨¼ãƒ†ã‚¹ãƒˆçµæœãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ"
                    }
                    self.logger.error("èªè¨¼ãƒ†ã‚¹ãƒˆå¤±æ•—")
                
                return summary
                
        except Exception as e:
            self.logger.error(f"èªè¨¼ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
            return {
                "status": "error",
                "error": str(e)
            }
    
    async def run_all_tests(self) -> Dict[str, Any]:
        """å…¨ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
        self.logger.info("\n" + "=" * 60)
        self.logger.info("TaxMCP å¤–éƒ¨ãƒ†ã‚¹ãƒˆçµ±åˆã‚¹ã‚¤ãƒ¼ãƒˆé–‹å§‹")
        self.logger.info(f"ãƒ†ã‚¹ãƒˆå¯¾è±¡: {self.base_url}")
        self.logger.info("=" * 60)
        
        # æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ
        if self.run_functional_tests:
            self.test_results["functional_tests"] = await self.run_functional_tests()
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ
        if self.run_performance_tests:
            self.test_results["performance_tests"] = await self.run_performance_tests()
        
        # èªè¨¼ãƒ†ã‚¹ãƒˆ
        if self.run_auth_tests:
            self.test_results["auth_tests"] = await self.run_auth_tests()
        
        # çµ±åˆçµæœã‚µãƒãƒªãƒ¼
        self.test_results["suite_end_time"] = datetime.now().isoformat()
        self.generate_integration_summary()
        
        return self.test_results
    
    def generate_integration_summary(self):
        """çµ±åˆãƒ†ã‚¹ãƒˆçµæœã‚µãƒãƒªãƒ¼ç”Ÿæˆ"""
        self.logger.info("\n" + "=" * 60)
        self.logger.info("çµ±åˆãƒ†ã‚¹ãƒˆçµæœã‚µãƒãƒªãƒ¼")
        self.logger.info("=" * 60)
        
        summary = {
            "overall_status": "success",
            "test_suites": {},
            "critical_issues": [],
            "recommendations": []
        }
        
        # æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆçµæœ
        if self.test_results["functional_tests"]:
            func_test = self.test_results["functional_tests"]
            if func_test["status"] == "completed":
                success_rate = func_test.get("success_rate", 0)
                summary["test_suites"]["functional"] = {
                    "status": "âœ“" if success_rate >= 90 else "âš ï¸" if success_rate >= 70 else "âœ—",
                    "success_rate": success_rate,
                    "details": f"{func_test.get('successful_tests', 0)}/{func_test.get('total_tests', 0)} æˆåŠŸ"
                }
                
                if success_rate < 90:
                    summary["critical_issues"].append(f"æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆæˆåŠŸç‡ãŒä½ã„: {success_rate:.1f}%")
                    if success_rate < 70:
                        summary["overall_status"] = "critical"
                
                self.logger.info(f"æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ: {summary['test_suites']['functional']['status']} {summary['test_suites']['functional']['details']} ({success_rate:.1f}%)")
            else:
                summary["test_suites"]["functional"] = {"status": "âœ—", "error": func_test.get("error", "ä¸æ˜ãªã‚¨ãƒ©ãƒ¼")}
                summary["critical_issues"].append("æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆãŒå®Ÿè¡Œã§ãã¾ã›ã‚“ã§ã—ãŸ")
                summary["overall_status"] = "critical"
                self.logger.error(f"æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ: âœ— {func_test.get('error', 'ä¸æ˜ãªã‚¨ãƒ©ãƒ¼')}")
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆçµæœ
        if self.test_results["performance_tests"]:
            perf_test = self.test_results["performance_tests"]
            if perf_test["status"] == "completed":
                meets_sla = perf_test.get("meets_sla", False)
                concurrent_results = perf_test.get("concurrent_test", {})
                avg_time = concurrent_results.get("response_times", {}).get("average_ms", 0)
                
                summary["test_suites"]["performance"] = {
                    "status": "âœ“" if meets_sla else "âš ï¸",
                    "meets_sla": meets_sla,
                    "avg_response_time_ms": avg_time
                }
                
                if not meets_sla:
                    summary["critical_issues"].append(f"ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹SLAæœªé”æˆ: å¹³å‡å¿œç­”æ™‚é–“ {avg_time}ms")
                    summary["recommendations"].append("ã‚µãƒ¼ãƒãƒ¼ãƒªã‚½ãƒ¼ã‚¹ã®å¢—å¼·ã¾ãŸã¯ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³æœ€é©åŒ–ã‚’æ¤œè¨ã—ã¦ãã ã•ã„")
                
                sla_status = "âœ“" if meets_sla else "âš ï¸"
                self.logger.info(f"ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ: {sla_status} SLA {'é”æˆ' if meets_sla else 'æœªé”æˆ'} (å¹³å‡: {avg_time}ms)")
            else:
                summary["test_suites"]["performance"] = {"status": "âœ—", "error": perf_test.get("error", "ä¸æ˜ãªã‚¨ãƒ©ãƒ¼")}
                summary["critical_issues"].append("ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆãŒå®Ÿè¡Œã§ãã¾ã›ã‚“ã§ã—ãŸ")
                self.logger.error(f"ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ: âœ— {perf_test.get('error', 'ä¸æ˜ãªã‚¨ãƒ©ãƒ¼')}")
        
        # èªè¨¼ãƒ†ã‚¹ãƒˆçµæœ
        if self.test_results["auth_tests"]:
            auth_test = self.test_results["auth_tests"]
            if auth_test["status"] == "completed":
                security_issues = auth_test.get("security_issues", 0)
                success_rate = auth_test.get("success_rate", 0)
                
                summary["test_suites"]["authentication"] = {
                    "status": "âœ“" if security_issues == 0 and success_rate >= 90 else "âš ï¸" if security_issues <= 1 else "âœ—",
                    "success_rate": success_rate,
                    "security_issues": security_issues
                }
                
                if security_issues > 0:
                    summary["critical_issues"].append(f"ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å•é¡ŒãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ: {security_issues}ä»¶")
                    summary["recommendations"].append("ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è¨­å®šã‚’è¦‹ç›´ã—ã€èªè¨¼æ©Ÿèƒ½ã‚’å¼·åŒ–ã—ã¦ãã ã•ã„")
                    if security_issues > 2:
                        summary["overall_status"] = "critical"
                
                security_status = "âœ“" if security_issues == 0 else "âš ï¸"
                self.logger.info(f"èªè¨¼ãƒ†ã‚¹ãƒˆ: {security_status} {auth_test.get('successful_tests', 0)}/{auth_test.get('total_tests', 0)} æˆåŠŸ, ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å•é¡Œ: {security_issues}ä»¶")
            else:
                summary["test_suites"]["authentication"] = {"status": "âœ—", "error": auth_test.get("error", "ä¸æ˜ãªã‚¨ãƒ©ãƒ¼")}
                summary["critical_issues"].append("èªè¨¼ãƒ†ã‚¹ãƒˆãŒå®Ÿè¡Œã§ãã¾ã›ã‚“ã§ã—ãŸ")
                self.logger.error(f"èªè¨¼ãƒ†ã‚¹ãƒˆ: âœ— {auth_test.get('error', 'ä¸æ˜ãªã‚¨ãƒ©ãƒ¼')}")
        
        # å…¨ä½“è©•ä¾¡
        if summary["overall_status"] == "success" and not summary["critical_issues"]:
            overall_emoji = "ğŸ‰"
            overall_message = "å…¨ã¦ã®ãƒ†ã‚¹ãƒˆãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸ"
        elif summary["overall_status"] == "critical":
            overall_emoji = "ğŸš¨"
            overall_message = "é‡å¤§ãªå•é¡ŒãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ"
        else:
            overall_emoji = "âš ï¸"
            overall_message = "ä¸€éƒ¨ã®ãƒ†ã‚¹ãƒˆã§å•é¡ŒãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ"
        
        self.logger.info(f"\n{overall_emoji} å…¨ä½“è©•ä¾¡: {overall_message}")
        
        # é‡è¦ãªå•é¡Œ
        if summary["critical_issues"]:
            self.logger.warning("\nğŸš¨ é‡è¦ãªå•é¡Œ:")
            for issue in summary["critical_issues"]:
                self.logger.warning(f"  - {issue}")
        
        # æ¨å¥¨äº‹é …
        if summary["recommendations"]:
            self.logger.info("\nğŸ’¡ æ¨å¥¨äº‹é …:")
            for rec in summary["recommendations"]:
                self.logger.info(f"  - {rec}")
        
        # çµæœã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        self.test_results["summary"] = summary
        self.save_results()
    
    def save_results(self):
        """çµæœã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        # è©³ç´°çµæœ
        detailed_file = f"integration_test_results_{timestamp}.json"
        with open(detailed_file, 'w', encoding='utf-8') as f:
            json.dump(self.test_results, f, ensure_ascii=False, indent=2)
        
        # ã‚µãƒãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆ
        summary_file = f"integration_test_summary_{timestamp}.json"
        with open(summary_file, 'w', encoding='utf-8') as f:
            json.dump(self.test_results["summary"], f, ensure_ascii=False, indent=2)
        
        self.logger.info(f"\nğŸ“„ è©³ç´°çµæœ: {detailed_file}")
        self.logger.info(f"ğŸ“„ ã‚µãƒãƒªãƒ¼: {summary_file}")
    
    def configure_tests(self, functional: bool = True, performance: bool = True, auth: bool = True):
        """ãƒ†ã‚¹ãƒˆå®Ÿè¡Œè¨­å®š"""
        self.run_functional_tests = functional
        self.run_performance_tests = performance
        self.run_auth_tests = auth
        
        enabled_tests = []
        if functional:
            enabled_tests.append("æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ")
        if performance:
            enabled_tests.append("ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ")
        if auth:
            enabled_tests.append("èªè¨¼ãƒ†ã‚¹ãƒˆ")
        
        self.logger.info(f"å®Ÿè¡Œäºˆå®šãƒ†ã‚¹ãƒˆ: {', '.join(enabled_tests)}")

async def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='TaxMCP çµ±åˆãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆ')
    parser.add_argument('--skip-functional', action='store_true', help='æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆã‚’ã‚¹ã‚­ãƒƒãƒ—')
    parser.add_argument('--skip-performance', action='store_true', help='ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆã‚’ã‚¹ã‚­ãƒƒãƒ—')
    parser.add_argument('--skip-auth', action='store_true', help='èªè¨¼ãƒ†ã‚¹ãƒˆã‚’ã‚¹ã‚­ãƒƒãƒ—')
    parser.add_argument('--functional-only', action='store_true', help='æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆã®ã¿å®Ÿè¡Œ')
    parser.add_argument('--performance-only', action='store_true', help='ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆã®ã¿å®Ÿè¡Œ')
    parser.add_argument('--auth-only', action='store_true', help='èªè¨¼ãƒ†ã‚¹ãƒˆã®ã¿å®Ÿè¡Œ')
    
    args = parser.parse_args()
    
    try:
        suite = IntegrationTestSuite()
        
        # ãƒ†ã‚¹ãƒˆè¨­å®š
        if args.functional_only:
            suite.configure_tests(functional=True, performance=False, auth=False)
        elif args.performance_only:
            suite.configure_tests(functional=False, performance=True, auth=False)
        elif args.auth_only:
            suite.configure_tests(functional=False, performance=False, auth=True)
        else:
            suite.configure_tests(
                functional=not args.skip_functional,
                performance=not args.skip_performance,
                auth=not args.skip_auth
            )
        
        # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
        results = await suite.run_all_tests()
        
        # çµ‚äº†ã‚³ãƒ¼ãƒ‰è¨­å®š
        if results["summary"]["overall_status"] == "critical":
            sys.exit(1)
        elif results["summary"]["critical_issues"]:
            sys.exit(2)
        else:
            sys.exit(0)
            
    except KeyboardInterrupt:
        print("\nãƒ†ã‚¹ãƒˆãŒä¸­æ–­ã•ã‚Œã¾ã—ãŸ")
        sys.exit(130)
    except Exception as e:
        print(f"ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
        sys.exit(1)

if __name__ == "__main__":
    asyncio.run(main())